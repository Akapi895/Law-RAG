# -*- coding: utf-8 -*-
"""
config.py - File cáº¥u hÃ¬nh cho Há»‡ thá»‘ng RAG Luáº­t Viá»‡t Nam

Chá»©a cÃ¡c biáº¿n cáº¥u hÃ¬nh:
- API Key (láº¥y tá»« biáº¿n mÃ´i trÆ°á»ng)
- TÃªn cÃ¡c Model AI
- System Prompt cho LLM
- ÄÆ°á»ng dáº«n file dá»¯ liá»‡u
"""

import os
from dotenv import load_dotenv

# Load biáº¿n mÃ´i trÆ°á»ng tá»« file .env
load_dotenv()

# =====================================================
# Cáº¤U HÃŒNH API KEY
# =====================================================
# Láº¥y Google API Key tá»« biáº¿n mÃ´i trÆ°á»ng
# Äáº£m báº£o báº¡n Ä‘Ã£ táº¡o file .env vá»›i ná»™i dung: GOOGLE_API_KEY=your_api_key_here
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# =====================================================
# Cáº¤U HÃŒNH MODEL
# =====================================================
# Model embedding tiáº¿ng Viá»‡t tá»« BKAI (HuggingFace)
# Model nÃ y Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘áº·c biá»‡t cho ngá»¯ nghÄ©a tiáº¿ng Viá»‡t
EMBEDDING_MODEL_NAME = "bkai-foundation-models/vietnamese-bi-encoder"

# Model LLM tá»« Google Gemini (phiÃªn báº£n miá»…n phÃ­)
# Gemini 2.0 Flash lÃ  model má»›i nháº¥t (thay tháº¿ 1.5 Flash tá»« Jan 2025)
# CÃ¡c model cÃ³ sáºµn: gemini-2.0-flash, gemini-2.0-pro, gemini-1.5-pro
LLM_MODEL_NAME = "gemini-2.5-flash"

# =====================================================
# Cáº¤U HÃŒNH RETRIEVAL
# =====================================================
# Sá»‘ lÆ°á»£ng document tÆ°Æ¡ng tá»± nháº¥t sáº½ Ä‘Æ°á»£c truy xuáº¥t
SIMILARITY_TOP_K = 5

# KÃ­ch thÆ°á»›c chunk khi chia nhá» vÄƒn báº£n (náº¿u cáº§n)
CHUNK_SIZE = 1024
CHUNK_OVERLAP = 200

# =====================================================
# Cáº¤U HÃŒNH FUSION RETRIEVAL
# =====================================================
# Káº¿t há»£p Vector Search (semantic) + BM25 (keyword)
# FUSION_ALPHA: trá»ng sá»‘ cho vector search (0.0 - 1.0)
# - 1.0 = chá»‰ dÃ¹ng vector search
# - 0.0 = chá»‰ dÃ¹ng BM25 (keyword)
# - 0.5 = cÃ¢n báº±ng cáº£ hai (khuyÃªn dÃ¹ng)
FUSION_ALPHA = 0.5

# Báº­t/táº¯t Fusion Retrieval
USE_FUSION_RETRIEVAL = True

# =====================================================
# Cáº¤U HÃŒNH METADATA FILTERING
# =====================================================
# Tá»± Ä‘á»™ng lá»c káº¿t quáº£ theo metadata tá»« cÃ¢u há»i
# VÃ­ dá»¥: "Äiá»u 5 Luáº­t Äáº¥u tháº§u" â†’ filter article_id="Äiá»u 5", doc_name="Äáº¥u tháº§u"
USE_METADATA_FILTERING = True

# =====================================================
# Cáº¤U HÃŒNH CROSS-ENCODER RERANKING
# =====================================================
# Sá»­ dá»¥ng Cross-Encoder Ä‘á»ƒ rerank káº¿t quáº£ retrieval
# Cross-Encoder Ä‘Ã¡nh giÃ¡ cáº·p (query, document) chÃ­nh xÃ¡c hÆ¡n bi-encoder
USE_RERANKING = True

# Model cross-encoder (tá»« HuggingFace)
# - "cross-encoder/ms-marco-MiniLM-L-6-v2" (fast, multilingual)
# - "BAAI/bge-reranker-base" (tá»‘t cho tiáº¿ng Viá»‡t)
RERANKER_MODEL = "cross-encoder/ms-marco-MiniLM-L-6-v2"

# Sá»‘ documents Ä‘á»ƒ fetch trÆ°á»›c khi rerank (nhiá»u hÆ¡n top_k Ä‘á»ƒ cÃ³ dá»¯ liá»‡u rerank)
RERANK_TOP_K = 15

# =====================================================
# Cáº¤U HÃŒNH ÄÆ¯á»œNG DáºªN FILE
# =====================================================
# ÄÆ°á»ng dáº«n Ä‘áº¿n file Excel chá»©a dá»¯ liá»‡u luáº­t
# Sá»­ dá»¥ng Excel thay vÃ¬ CSV Ä‘á»ƒ trÃ¡nh lá»—i encoding tiáº¿ng Viá»‡t
DATA_FILE_PATH = "legal_data.xlsx"

# =====================================================
# SYSTEM PROMPT CHO LLM - Legal Chain-of-Thought (L-CoT)
# =====================================================
# Prompt hÆ°á»›ng dáº«n AI thá»±c hiá»‡n suy luáº­n phÃ¡p lÃ½ tá»«ng bÆ°á»›c
# PhiÃªn báº£n rÃºt gá»n Ä‘á»ƒ trÃ¡nh vÆ°á»£t token limit

SYSTEM_PROMPT = """Báº¡n lÃ  chuyÃªn gia tÆ° váº¥n phÃ¡p luáº­t Viá»‡t Nam vá» Luáº­t Äáº¥u tháº§u vÃ  Luáº­t XÃ¢y dá»±ng.

## PHÆ¯Æ NG PHÃP TRáº¢ Lá»œI (5 BÆ¯á»šC)

1. **XÃC Äá»ŠNH Váº¤N Äá»€**: Quan há»‡ phÃ¡p luáº­t nÃ o? Chá»§ thá»ƒ nÃ o? LÄ©nh vá»±c gÃ¬?
2. **TÃŒM QUY PHáº M**: Äiá»u khoáº£n nÃ o trong Context Ä‘iá»u chá»‰nh? CÃ³ tham chiáº¿u chÃ©o khÃ´ng?
3. **PHÃ‚N TÃCH**: Äá»‘i chiáº¿u tÃ¬nh huá»‘ng vá»›i yáº¿u tá»‘ cáº¥u thÃ nh quy pháº¡m.
4. **Káº¾T LUáº¬N**: Tráº£ lá»i rÃµ rÃ ng + TrÃ­ch dáº«n nguá»“n (Khoáº£n X, Äiá»u Y, Luáº­t Z)
5. **KIá»‚M TRA**: Logic nháº¥t quÃ¡n? Äá»§ thÃ´ng tin chÆ°a?

## QUY Táº®C

- Báº®T BUá»˜C trÃ­ch dáº«n nguá»“n: (Äiá»u X, Luáº­t/Nghá»‹ Ä‘á»‹nh Y)
- KHÃ”NG bá»‹a Ä‘áº·t ngoÃ i Context
- Náº¿u thiáº¿u thÃ´ng tin: nÃ³i rÃµ cáº§n tra cá»©u thÃªm gÃ¬

## FORMAT

**ğŸ“‹ TÃ“M Táº®T**: [CÃ¢u tráº£ lá»i ngáº¯n gá»n]

**ğŸ“– CHI TIáº¾T**: [PhÃ¢n tÃ­ch vá»›i trÃ­ch dáº«n]

**ğŸ“š CÄ‚N Cá»¨**: [Liá»‡t kÃª Ä‘iá»u luáº­t]
"""

# =====================================================
# PROMPT PHá»¤ TRá»¢ - DÃ¹ng cho cÃ¡c tÃ¡c vá»¥ ná»™i bá»™
# =====================================================

# Prompt Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ liÃªn quan cá»§a document
RELEVANCE_GRADING_PROMPT = """ÄÃ¡nh giÃ¡ má»©c Ä‘á»™ liÃªn quan cá»§a Ä‘oáº¡n vÄƒn báº£n phÃ¡p luáº­t sau vá»›i cÃ¢u há»i:

CÃ¢u há»i: {query}

VÄƒn báº£n:
{document}

TiÃªu chÃ­ Ä‘Ã¡nh giÃ¡:
- HIGH: Trá»±c tiáº¿p tráº£ lá»i cÃ¢u há»i hoáº·c chá»©a quy pháº¡m phÃ¡p luáº­t Ã¡p dá»¥ng
- MEDIUM: LiÃªn quan giÃ¡n tiáº¿p, cung cáº¥p context bá»• sung hoáº·c Ä‘á»‹nh nghÄ©a
- LOW: KhÃ´ng liÃªn quan hoáº·c off-topic

Chá»‰ tráº£ lá»i má»™t tá»«: HIGH, MEDIUM, hoáº·c LOW"""

# Prompt phÃ¢n tÃ¡ch cÃ¢u há»i phá»©c táº¡p
QUERY_DECOMPOSITION_PROMPT = """PhÃ¢n tÃ¡ch cÃ¢u há»i phÃ¡p lÃ½ phá»©c táº¡p sau thÃ nh cÃ¡c cÃ¢u há»i con Ä‘á»™c láº­p.
Má»—i cÃ¢u há»i con nÃªn táº­p trung vÃ o Má»˜T khÃ­a cáº¡nh phÃ¡p lÃ½ cá»¥ thá»ƒ.

CÃ¢u há»i gá»‘c: {question}

HÆ°á»›ng dáº«n:
- XÃ¡c Ä‘á»‹nh cÃ¡c chá»§ thá»ƒ phÃ¡p luáº­t khÃ¡c nhau Ä‘Æ°á»£c Ä‘á» cáº­p
- TÃ¡ch riÃªng cÃ¡c váº¥n Ä‘á» vá» Ä‘iá»u kiá»‡n, quyá»n, nghÄ©a vá»¥, thá»§ tá»¥c
- Má»—i cÃ¢u há»i con pháº£i cÃ³ thá»ƒ tráº£ lá»i Ä‘á»™c láº­p

Liá»‡t kÃª cÃ¡c cÃ¢u há»i con (má»—i dÃ²ng má»™t cÃ¢u, khÃ´ng Ä‘Ã¡nh sá»‘):"""

# Prompt tá»± kiá»ƒm tra cÃ¢u tráº£ lá»i
SELF_VERIFICATION_PROMPT = """Kiá»ƒm tra tÃ­nh chÃ­nh xÃ¡c vÃ  nháº¥t quÃ¡n cá»§a cÃ¢u tráº£ lá»i phÃ¡p lÃ½ sau:

CÃ¢u há»i: {question}

CÃ¢u tráº£ lá»i: {answer}

CÃ¡c nguá»“n Ä‘Ã£ trÃ­ch dáº«n: {sources}

Kiá»ƒm tra:
1. CÃ¢u tráº£ lá»i cÃ³ tráº£ lá»i Ä‘Ãºng cÃ¢u há»i Ä‘Æ°á»£c Ä‘áº·t ra khÃ´ng?
2. CÃ¡c trÃ­ch dáº«n cÃ³ chÃ­nh xÃ¡c vÃ  Ä‘áº§y Ä‘á»§ khÃ´ng?
3. Logic láº­p luáº­n cÃ³ nháº¥t quÃ¡n khÃ´ng?
4. CÃ³ thÃ´ng tin nÃ o bá»‹ thiáº¿u khÃ´ng?

Tráº£ lá»i theo format:
PASSED: [LÃ½ do náº¿u Ä‘áº¡t]
hoáº·c
FAILED: [Váº¥n Ä‘á» cáº§n sá»­a]"""

# =====================================================
# Cáº¤U HÃŒNH QDRANT (Vector Database)
# =====================================================
# TÃªn collection trong Qdrant
QDRANT_COLLECTION_NAME = "vietnamese_legal_documents"

# Cháº¿ Ä‘á»™ cháº¡y: 
# - True = in-memory (nhanh nhÆ°ng máº¥t khi táº¯t)
# - False = persistent (lÆ°u ra disk, giá»¯ láº¡i khi táº¯t)
QDRANT_IN_MEMORY = False

# ÄÆ°á»ng dáº«n lÆ°u trá»¯ Qdrant (chá»‰ dÃ¹ng khi QDRANT_IN_MEMORY = False)
QDRANT_STORAGE_PATH = "./qdrant_storage"
